# Honest Cross-Site Validation - Quick Test
# ==========================================
# Quick test with reduced pipeline combinations for debugging.
# Runs 32 combinations (4 atlases × 2 FC types × 1 strategy × 2 GSR × 2 directions).
#
# Usage:
#   # Run from repo root:
#   source venv/bin/activate && python -m benchmarking.cross_site --config configs/cross_site_quick.yaml

# Data paths
data_path: "~/Yandex.Disk.localized/IHB/OpenCloseBenchmark_data"

# Datasets - bidirectional for quick test
train_on:
  - china
  - ihb
test_on:
  - china
  - ihb

# Pipeline parameters (minimal for testing)
atlases:
  - AAL
  - Schaefer200
  - Brainnetome
  - HCPex

fc_types:
  - corr
  - tangent

strategies: [4]  # aCompCor + 24P (common choice)

gsr_options:
  - noGSR
  - GSR

# Model settings
pca_components: 0.95
random_state: 42

# Classifier (extensible)
# Options: `logreg`, `svm_rbf`
model:
  name: logreg
  # To run SVM with RBF kernel:
  # name: svm_rbf
  # params: {C: 1.0, gamma: scale}
  params:
    solver: lbfgs
    max_iter: 1000
  scale: false  # auto-true for svm_rbf if omitted

# Save per-sample test outputs (predictions + scores) for paired comparisons
# (Exact McNemar, DeLong). Writes `*_test_outputs.csv`.
save_test_outputs: true

# Permutation testing (0 = skip, >0 = number of permutations)
n_permutations: 100  # Quick: 100 permutations for testing

# Multiprocessing
n_workers: 2  # Lower for quick test

# Output
output: "results/cross_site_quick.csv"
